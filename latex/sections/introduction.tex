% Word budget: ~300 words

% Who is the project for?
% What are you hoping to achieve for your users/audience?
% What are you hoping to learn or find out through your project?
% How will you demonstrate that your project fulfils its aims?

\chapter{Introduction}
Long bone fractures are a frequent effect of high-energy trauma \autocite{HStein1999}, among which tibial fractures of the lower extremities are the most common. These fractures require long-term follow-up, where after initial fixation the fracture site must be re-examined at regular intervals for callus formation\footnote{The development of cartilaginous material containing bone-forming cells.}, bridging, and union \autocite{Jones2020}. Whelan et al's Radiographic Union Score for Tibial Fractures (RUST score) is a discrete 12-point scale that serves a common metric for the assessment of union from the lateral and anteroposterior\footnote{i.e.\ front-to-back.} radiograph of a fracture \autocite{Whelan2010}. This project proposes a means to automate the assessment of fracture healing, by using machine learning to classify radiographs of tibial fractures according to their RUST Scores.

\section{Aims and Motivation}

Non-union and delayed union are significant complications in fracture healing, one which results in heightened morbidity, loss-of-function, and infection risk \autocite{Nicholson2021}. As a result, it is important for physicians to determine non-union events so that further treatment and corrective surgery may be taken. Although non-union may be determined through a variety of clinical assessments (e.g.\ palpation, weight-bearing), the RUST score is emerging as a quantitative radiography-based measure with high consistency \autocite{Panchoo2022}, biomechanical correlativity \autocite{Cook2018}, and good guidance for postoperative rehabilitation \autocite{Debuka2019}. However, in order to assess a fracture using the RUST score, a orthopaedic must examine at least two radiographs (one lateral, one anteroposterior) for callus formation --- a non-trivial process.

Recent advances in deep learning, coupled with the increasing availability of large radiographic datasets (e.g. CheXpert, LERA, MURA) \autocites{CheXpert2019}{LERA}{MURA2017} offer the possibility of automating the process of fracture classification. Certain research models such as Rajpurkar et al's DNN ConvNet are able to meet, or exceed radiologist-level performance for abnormality classification in specific anatomical domains \autocite{MURA2017}, and as of 2021 commercial developments are beginning to see regulatory clearance\footnote{Authorisation for real-world clinical use by national health agencies like the Food and Drug Administration (FDA), Health Canada, \emph{Conformité Européenne}, etc.} \autocite{Adams2021}.

However, much of the current available literature\footnote{A selection of which are analysed with commentary in \autoref{background}.} is focused on the mere detection and classification of fractures (i.e. abnormality detection). Such models either perform binary classification (e.g. \enquote{Is this a \emph{normal} radiograph?}), multi-class (e.g. \enquote{Is this a \emph{leg}, \emph{arm}, or \emph{knee} fracture?}), or localisation (e.g. \enquote{Where \emph{is} the fracture on this radiograph?}). Comparatively less work has been done on the \emph{characterisation} of radiographs, where the properties of a fracture are described \autocite{Tanzi2020}. This gap in the field offers opportunity for further investigation, especially as it is not the mere presence of a fracture which informs medical decision-making, but rather its severity and properties. By creating an machine learning model where the RUST-score of a fracture is inferred from a radiograph, we hope to advance the state of AI in medical imaging, and develop better diagnostic tooling.

\section{Objectives and Evaluation}

% The goal of this project, is to develop an AI model that is able to take a pair of input radiographs, and output a projected RUST score. As the RUST score is a sum derived from the characterization of a fracture from four different tibial cortices\footnote{The cortex is the outermost layer of the bone.} (the anterior, posterior, lateral, and medial cortex) \autocite{Whelan2010}, the model must process input in pairs of two radiographs. 

% The objective of this project is to develop an AI model that is able to receive pairs of input radiographs, and output a projected RUST numeric rust score, as well as a heatmap of features that the model detects. As the RUST score is a sum derived from the characterization of a fracture from four different tibial cortices\footnote{The cortex is the outermost layer of the bone. The RUST Score relies on an examination of the anterior, posterior, lateral, and medial cortex of the tibia. \autocite{Whelan2010}}, the model must process input in pairs of two radiographs. As our dataset is limited to only a few thousand samples, we will be using transfer learning to train a broader, general-purpose model on our domain specific task.\footnote{See \autoref{methodology} for further information.}

The objective of this project is to develop an AI model using transfer learning that is able to predict the RUST score of a pair of anteroposterior and lateral radiographs. We will evaluate two different transfer learning approaches based on the InceptionV3 model architecture\autocite{inceptionv3}.
The first model will use InceptionV3 trained with the general-purpose ImageNet dataset \autocite{imagenet}.
The second model will use the same InceptionV3 architecture, but trained with the domain-specific RadImageNet dataset \autocite{radimagenet}. The development and comparative evaluation of these two \enquote*{base} models for transfer learning will allow us to compare and contrast the use of a model pre-trained on a general-purpose dataset (ImageNet) versus a model pre-trained on a slightly smaller, but domain-specific dataset (RadImageNet).

\clearpage
\subsection{Project Specification}

Thus, the aims of this project can be summarised as the following three objectives:

\begin{itemize}
    \item Evaluate the performance of InceptionV3 trained with ImageNet and RadImageNet on a transfer learning task.
    \item Develop and optimise the best-performing transfer learning model for use in the automated assessment of fracture healing through RUST scores.
    \item Assess model performance through it's AUROC (Area Under Receiver Operating Characteristic) value.\footnote{See \ref{AUROC} for further information.}
\end{itemize}

% https://en.wikipedia.org/wiki/Receiver_operating_characteristic